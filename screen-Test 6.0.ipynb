{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63649962-fcb6-4107-9199-0fbc943214a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "735557de-9bc6-4d39-8d7d-483a1fca45ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d386cf0-bc6c-4d9f-ac4c-723a95c72306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(df, feature_config):\n",
    "    X = df.copy()\n",
    "    transformers = []\n",
    "    ohe_columns = []\n",
    "\n",
    "    for feature_name, params in feature_config.items():\n",
    "        if params['is_selected']:\n",
    "            feature_type = params['feature_variable_type']\n",
    "            details = params['feature_details']\n",
    "            missing_values_strategy = details.get('missing_values', 'None')\n",
    "            impute_with = details.get('impute_with', 'None')\n",
    "            impute_value = details.get('impute_value', 0)\n",
    "\n",
    "            if feature_type == 'numerical':\n",
    "                if missing_values_strategy == 'Impute':\n",
    "                    if impute_with == 'Average of values':\n",
    "                        transformers.append((feature_name, SimpleImputer(strategy='mean'), [feature_name]))\n",
    "                    elif impute_with == 'custom':\n",
    "                        transformers.append((feature_name, SimpleImputer(strategy='constant', fill_value=impute_value), [feature_name]))\n",
    "            elif feature_type == 'text':\n",
    "                if missing_values_strategy == 'Impute':\n",
    "                    transformers.append((feature_name, SimpleImputer(strategy='constant', fill_value='missing'), [feature_name]))\n",
    "                ohe = OneHotEncoder(sparse=False)\n",
    "                transformers.append((feature_name, ohe, [feature_name]))\n",
    "                ohe_columns.append(feature_name)\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers, remainder='passthrough')\n",
    "    X_transformed = preprocessor.fit_transform(X)\n",
    "    \n",
    "    new_columns = []\n",
    "    for feature_name, params in feature_config.items():\n",
    "        if params['is_selected']:\n",
    "            if params['feature_variable_type'] == 'text':\n",
    "                ohe = preprocessor.named_transformers_[feature_name]\n",
    "                categories = ohe.categories_[0]\n",
    "                new_columns.extend([f\"{feature_name}_{category}\" for category in categories])\n",
    "            else:\n",
    "                new_columns.append(feature_name)\n",
    "    \n",
    "    return pd.DataFrame(X_transformed, columns=new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a54a13f-a354-4605-930d-8d119127ec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df, feature_generation_config):\n",
    "    for interaction in feature_generation_config.get('linear_interactions', []):\n",
    "        feature_name = f'{interaction[0]}_{interaction[1]}_interaction'\n",
    "        df[feature_name] = df[interaction[0]] * df[interaction[1]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65ee7156-85a1-4c02-baa8-1ba0fb71def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_features(X, method, num_features):\n",
    "    if method == 'PCA':\n",
    "        pca = PCA(n_components=num_features)\n",
    "        X_reduced = pca.fit_transform(X)\n",
    "        return X_reduced\n",
    "    else:\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78bde91e-ca44-4d33-a2db-1d87a1abb2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(df, target_column):\n",
    "    return df[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15c175d5-394e-40c7-a0b9-a147ce75502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_and_train_model(X, y, model_config):\n",
    "    if model_config['RandomForestRegressor']['is_selected']:\n",
    "        model = RandomForestRegressor()\n",
    "        param_grid = {\n",
    "            'n_estimators': range(model_config['RandomForestRegressor']['min_trees'], model_config['RandomForestRegressor']['max_trees'] + 1),\n",
    "            'max_depth': range(model_config['RandomForestRegressor']['min_depth'], model_config['RandomForestRegressor']['max_depth'] + 1),\n",
    "            'min_samples_leaf': range(model_config['RandomForestRegressor']['min_samples_per_leaf_min_value'], model_config['RandomForestRegressor']['min_samples_per_leaf_max_value'] + 1)\n",
    "        }\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, error_score='raise')\n",
    "        try:\n",
    "            grid_search.fit(X, y)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error during model training: {e}\")\n",
    "            return None, None, None\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        return best_model, best_params, grid_search.cv_results_\n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad9c4a83-ad67-4ed0-b9c5-e1202cf6408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(json_file_path):\n",
    "    config = load_json(json_file_path)\n",
    "    dataset_path = config['design_state_data']['session_info']['dataset']\n",
    "    df = load_dataset(dataset_path)\n",
    "    X = preprocess_features(df, config['design_state_data']['feature_handling'])\n",
    "    \n",
    "    X = generate_features(X, config['design_state_data']['feature_generation'])\n",
    "    \n",
    "    reduction_method = config['design_state_data']['feature_reduction']['feature_reduction_method']\n",
    "    num_features_to_keep = int(config['design_state_data']['feature_reduction']['num_of_features_to_keep'])\n",
    "    \n",
    "    X = reduce_features(X, reduction_method, num_features_to_keep)\n",
    "    target_column = config['design_state_data']['target']['target']\n",
    "    y = get_target(df, target_column)\n",
    "    \n",
    "    if df[target_column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model, best_params, cv_results = select_and_train_model(X_train, y_train, config['design_state_data']['algorithms'])\n",
    "    \n",
    "    if model:\n",
    "        print(\"Best Model:\", model)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        print(f\"R² Score: {r2:.4f}\")\n",
    "        print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    else:\n",
    "        print(\"Model training failed. Check the error messages for details.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14fff4ba-a1fd-40a8-b495-128a0fb481d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: RandomForestRegressor(max_depth=22, min_samples_leaf=5, n_estimators=15)\n",
      "R² Score: 0.9977\n",
      "Mean Squared Error: 0.0015\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    json_file_path = \"C:\\\\Users\\\\Bhumikka Pancharane\\\\Downloads\\\\DS_Assignment - internship\\\\Screening Test - DS\\\\data.json\"\n",
    "    main(json_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
